{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_mm1YfhG8rzQ",
        "FC0ATmtZRjYA",
        "oDEIXBSjXL5e",
        "vQNcHFD1VyuG",
        "pMpd5Sw9st7Z",
        "l-74I50D6M-L",
        "u0DP19b6XLot",
        "Zno7j6fmBz5L"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TESTING"
      ],
      "metadata": {
        "id": "RyPHy3GgBt0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip Marlena.zip"
      ],
      "metadata": {
        "id": "zNgno-sqHcUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from XMTR import MTR\n",
        "from GlobalLocalVariants import GlobalSurrogateTree, LocalSurrogateTree\n",
        "from Marlena.algorithms.MARLENA.marlena.marlena.marlena import MARLENA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.io import arff\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore')\n",
        "import time\n",
        "import csv\n",
        "\n",
        "def calc_al_error(instance, perc):\n",
        "  # the error should be non zero\n",
        "  return (instance+0.1)*perc \n",
        "\n",
        "\n",
        "def rule_cov(instance, feature_names, rule):\n",
        "  covered = True\n",
        "  for k in range(len(instance)):\n",
        "    feature = feature_names[k]\n",
        "    if feature in rule.keys():\n",
        "      if type(rule[feature][0]) == list: # for GS/LS\n",
        "        for lst in rule[feature]:\n",
        "          if lst[0] == '>' and instance[k] <= lst[1]:\n",
        "            return 0\n",
        "          if lst[0] == '<=' and instance[k] > lst[1]:\n",
        "            return 0\n",
        "      else: # if it comes from MTR\n",
        "          if instance[k] > rule[feature][1]:  # 1=max\n",
        "              return 0\n",
        "          if instance[k] < rule[feature][0]:  # 0=min\n",
        "              return 0\n",
        "  return 1\n",
        "\n",
        "\n",
        "def calcMae(actualPred, MTRpred, GSpred, LSpred, MARLENApreds):\n",
        "  # mae MTR local error\n",
        "  MTRerrors = np.array([subarray[:,1] for subarray in MTRpred])\n",
        "  MTRpreds = np.array([subarray[:,0] for subarray in MTRpred])\n",
        "  column_errors = np.mean(MTRerrors, axis=0)\n",
        "  maeActual_with_error = np.mean(MTRerrors, axis=0)\n",
        "\n",
        "  # mae MTR/GS without local error\n",
        "  maeGS = mean_absolute_error(GSpred, MTRpreds, multioutput=\"raw_values\")\n",
        "\n",
        "  # mae MTR/LS without local error\n",
        "  maeLS = mean_absolute_error(LSpred, MTRpreds, multioutput=\"raw_values\")\n",
        "\n",
        "  # mae MTR/MARLENA without local error\n",
        "  maeMAR = mean_absolute_error(MARLENApreds, MTRpreds, multioutput=\"raw_values\")\n",
        "\n",
        "  return [maeActual_with_error, maeGS, maeLS, maeMAR]\n",
        "\n",
        "def doTest(X_train, X_test, y_train, y_test, f_n, t_n, percentage): \n",
        "  # train models\n",
        "  print('   training MTR...') \n",
        "  MTR_obj = MTR(model=None, X_train = X_train, X_test=X_test, y_train=y_train, y_test=y_test, feature_names=f_n, target_names=t_n)\n",
        "  model = MTR_obj.getModel()\n",
        "  predictions = model.predict(X_train)\n",
        "\n",
        "  print('   training GS...') \n",
        "  GS = GlobalSurrogateTree(X_train, predictions, f_n)\n",
        "  print('   training LS...') \n",
        "  LS = LocalSurrogateTree(X_train, predictions, f_n, 20) # neigns should be >= 10\n",
        "  print('   training Marlena...')\n",
        "  marlena = MARLENA(neigh_type='mixed', random_state=42)\n",
        "\n",
        "\n",
        "  actualpreds = []\n",
        "  MTRpreds = []\n",
        "  GSpreds = []\n",
        "  LSpreds = []\n",
        "  MARLENApreds = []\n",
        "\n",
        "  time_response = {'MTR': [], 'GS': [], 'LS': [], 'MARLENA': []}\n",
        "  avgEstimators = []\n",
        "  coverage = np.array([0,0,0,0])\n",
        "  avgRuleLengths = np.array([0,0,0,0])\n",
        "  for i in range(len(X_test)):\n",
        "    print(\"   \",i+1,\"/\", len(X_test), \"tests\")\n",
        "    inside_coverage = np.array([0,0,0,0])\n",
        "    instance = X_test[i]\n",
        "    # actual\n",
        "    actualpreds.append(y_test[i])\n",
        "\n",
        "    # MTR\n",
        "    error = calc_al_error(y_test[i], percentage)\n",
        "    ts = time.time()\n",
        "    MTRrule = MTR_obj.explain(instance, error) # explain instance\n",
        "    te = time.time() - ts\n",
        "    time_response['MTR'].append(te)\n",
        "    estimators = MTR_obj.getAmountOfReduction() # get estimators\n",
        "    avgEstimators.append(estimators[0])\n",
        "    decisionsAndErrors = MTR_obj.getDecisionsAndErros() # get preds/errors\n",
        "    MTRpreds.append(decisionsAndErrors)\n",
        "    feature_limits = MTR_obj.getFeatureLimits()\n",
        "    avgRuleLengths[0] += len(feature_limits.keys())\n",
        "\n",
        "    # GS \n",
        "    ts = time.time()\n",
        "    GSrule, GSprediction = GS.rule(instance)\n",
        "    te = time.time() - ts\n",
        "    time_response['GS'].append(te)\n",
        "    GSpreds.append(GSprediction)\n",
        "    avgRuleLengths[1] += len(GSrule.keys())\n",
        "\n",
        "    # LS\n",
        "    ts = time.time()\n",
        "    LSrule, LSprediction = LS.rule(instance)\n",
        "    te = time.time() - ts\n",
        "    time_response['LS'].append(te)\n",
        "    LSpreds.append(LSprediction)\n",
        "    avgRuleLengths[2] += len(LSrule.keys())\n",
        "\n",
        "    # MARLENA\n",
        "    i2e = pd.Series(instance, index=f_n)\n",
        "    X2E = pd.DataFrame(X_train, columns=f_n)\n",
        "    ts = time.time()\n",
        "    # returns rule, mask(MarlenaPrediction), list_split_conditions, len_rule, instance_imporant_feat, fidelity, hit, DT\n",
        "    _, MarlenaPrediction, list_split_conditions, len_rule, _, _, _, _ = marlena.extract_explanation(i2e, X2E, model, f_n, [],\n",
        "                                              t_n, k=10, size=50, alpha=0.7)\n",
        "    te = time.time() - ts\n",
        "    time_response['MARLENA'].append(te)\n",
        "    MARLENApreds.append(MarlenaPrediction)\n",
        "    avgRuleLengths[3] += len_rule #len(list_split_conditions.keys())\n",
        "\n",
        "    # calculate the coverage\n",
        "    for test_instance in X_test:\n",
        "      MTRcov = rule_cov(test_instance, f_n, feature_limits)\n",
        "      GScov = rule_cov(test_instance, f_n, GSrule) \n",
        "      LScov = rule_cov(test_instance, f_n, LSrule) \n",
        "      MARcov = rule_cov(test_instance, f_n, list_split_conditions) \n",
        "      inside_coverage[0] += MTRcov\n",
        "      inside_coverage[1] += GScov\n",
        "      inside_coverage[2] += LScov\n",
        "      inside_coverage[3] += MARcov\n",
        "    coverage = np.add(coverage, inside_coverage/len(X_test))\n",
        "\n",
        "  actualpreds = np.array(actualpreds)\n",
        "  MTRpreds = np.array(MTRpreds)\n",
        "  GSpreds = np.array(GSpreds)\n",
        "  LSpreds = np.array(LSpreds)\n",
        "  MARLENApreds = np.array(MARLENApreds)\n",
        "\n",
        "  coverage = coverage/len(X_test)\n",
        "\n",
        "  avgRuleLengths = avgRuleLengths/len(X_test)\n",
        "  maeResults = calcMae(actualpreds, MTRpreds, GSpreds, LSpreds, MARLENApreds)\n",
        "\n",
        "  #print('MTR|', \"mae: \", maeResults[0].round(3), \"| ruleL:\", avgRuleLengths[0], \"| TIME:\", np.array(time_response['MTR']).mean(), \"| Coverage:\",coverage[0], \"| avg estimators:\", round(np.array(avgEstimators).mean(),3),\"/\",estimators[1])\n",
        "  #print(' GS|', \"mae: \", maeResults[1].round(3), \"| ruleL:\", avgRuleLengths[1], \"| TIME:\", np.array(time_response['GS']).mean(), \"| Coverage:\",coverage[1])\n",
        "  #print(' LS|', \"mae: \", maeResults[2].round(3), \"| ruleL:\", avgRuleLengths[2], \"| TIME:\", np.array(time_response['LS']).mean(), \"| Coverage:\",coverage[2])\n",
        "  #print('MAR|', \"mae: \", maeResults[3].round(3), \"| ruleL:\", avgRuleLengths[3], \"| TIME:\", np.array(time_response['MARLENA']).mean(), \"| Coverage:\",coverage[3])\n",
        "  return maeResults, avgRuleLengths, time_response, coverage, np.array(avgEstimators).mean(), estimators[1]"
      ],
      "metadata": {
        "id": "Wulp_TlYO8zV"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######\n",
        "# only needs X,y, f_n, t_n and allowed error\n",
        "######\n",
        "maeResults_all = {'MTR': [], 'GS': [], 'LS': [], 'MARLENA': []}\n",
        "avgRuleLengths_all = {'MTR': [], 'GS': [], 'LS': [], 'MARLENA': []}\n",
        "time_response_all = {'MTR': [], 'GS': [], 'LS': [], 'MARLENA': []}\n",
        "coverage_all = {'MTR': [], 'GS': [], 'LS': [], 'MARLENA': []}\n",
        "avgEstimators_all = {'reduced': [], 'original': []}\n",
        "\n",
        "kf = KFold(n_splits=15, shuffle=True, random_state=42)\n",
        "counter = 1\n",
        "for train_index, test_index in kf.split(X):\n",
        "  X_train, X_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "  print(\"iteration:\", counter)\n",
        "  counter += 1\n",
        "  results = doTest(X_train, X_test, y_train, y_test, f_n, t_n, 0.1)\n",
        "\n",
        "  # mae \n",
        "  maeResults_all['MTR'].append(results[0][0])\n",
        "  maeResults_all['GS'].append(results[0][1])\n",
        "  maeResults_all['LS'].append(results[0][2])\n",
        "  maeResults_all['MARLENA'].append(results[0][3])\n",
        "\n",
        "  # RL\n",
        "  avgRuleLengths_all['MTR'].append(results[1][0])\n",
        "  avgRuleLengths_all['GS'].append(results[1][1])\n",
        "  avgRuleLengths_all['LS'].append(results[1][2])\n",
        "  avgRuleLengths_all['MARLENA'].append(results[1][3])\n",
        "\n",
        "  # time\n",
        "  time_response_all['MTR'].append(np.array(results[2]['MTR']).mean())\n",
        "  time_response_all['GS'].append(np.array(results[2]['GS']).mean())\n",
        "  time_response_all['LS'].append(np.array(results[2]['LS']).mean())\n",
        "  time_response_all['MARLENA'].append(np.array(results[2]['MARLENA']).mean())\n",
        "\n",
        "  # coverage\n",
        "  coverage_all['MTR'].append(results[3][0])\n",
        "  coverage_all['GS'].append(results[3][1])\n",
        "  coverage_all['LS'].append(results[3][2])\n",
        "  coverage_all['MARLENA'].append(results[3][3])\n",
        "\n",
        "  # estimators\n",
        "  avgEstimators_all['reduced'].append(results[4])\n",
        "  avgEstimators_all['original'].append(results[5])\n",
        "\n",
        "print('MTR|', \"mae: \", np.array(maeResults_all['MTR']).mean(axis=0).round(3),     \"| ruleL:\", np.array(avgRuleLengths_all['MTR']).mean(),     \"| TIME:\", np.array(time_response_all['MTR']).mean(),     \"| Coverage:\",np.array(coverage_all['MTR']).mean(), \"| avg estimators:\", round(np.array(avgEstimators_all['reduced']).mean(),3),\"/\",np.array(avgEstimators_all['original']).mean())\n",
        "print(' GS|', \"mae: \", np.array(maeResults_all['GS']).mean(axis=0).round(3),      \"| ruleL:\", np.array(avgRuleLengths_all['GS']).mean(),      \"| TIME:\", np.array(time_response_all['GS']).mean(),      \"| Coverage:\",np.array(coverage_all['GS']).mean())\n",
        "print(' LS|', \"mae: \", np.array(maeResults_all['LS']).mean(axis=0).round(3),      \"| ruleL:\", np.array(avgRuleLengths_all['LS']).mean(),      \"| TIME:\", np.array(time_response_all['LS']).mean(),      \"| Coverage:\",np.array(coverage_all['LS']).mean())\n",
        "print('MAR|', \"mae: \", np.array(maeResults_all['MARLENA']).mean(axis=0).round(3), \"| ruleL:\", np.array(avgRuleLengths_all['MARLENA']).mean(), \"| TIME:\", np.array(time_response_all['MARLENA']).mean(), \"| Coverage:\",np.array(coverage_all['MARLENA']).mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8ws3OUldQRV",
        "outputId": "494fdf02-02e0-4d42-f318-185afd9d04d9"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration: 1\n",
            "   training MTR...\n",
            "   training GS...\n",
            "   training LS...\n",
            "   training Marlena...\n",
            "    1 / 7 tests\n",
            "    2 / 7 tests\n",
            "    3 / 7 tests\n",
            "    4 / 7 tests\n",
            "    5 / 7 tests\n",
            "    6 / 7 tests\n",
            "    7 / 7 tests\n",
            "iteration: 2\n",
            "   training MTR...\n",
            "   training GS...\n",
            "   training LS...\n",
            "   training Marlena...\n",
            "    1 / 7 tests\n",
            "    2 / 7 tests\n",
            "    3 / 7 tests\n",
            "    4 / 7 tests\n",
            "    5 / 7 tests\n",
            "    6 / 7 tests\n",
            "    7 / 7 tests\n",
            "iteration: 3\n",
            "   training MTR...\n",
            "   training GS...\n",
            "   training LS...\n",
            "   training Marlena...\n",
            "    1 / 7 tests\n",
            "    2 / 7 tests\n",
            "    3 / 7 tests\n",
            "    4 / 7 tests\n",
            "    5 / 7 tests\n",
            "    6 / 7 tests\n",
            "    7 / 7 tests\n",
            "iteration: 4\n",
            "   training MTR...\n",
            "   training GS...\n",
            "   training LS...\n",
            "   training Marlena...\n",
            "    1 / 7 tests\n",
            "    2 / 7 tests\n",
            "    3 / 7 tests\n",
            "    4 / 7 tests\n",
            "    5 / 7 tests\n",
            "    6 / 7 tests\n",
            "    7 / 7 tests\n",
            "iteration: 5\n",
            "   training MTR...\n",
            "   training GS...\n",
            "   training LS...\n",
            "   training Marlena...\n",
            "    1 / 7 tests\n",
            "    2 / 7 tests\n",
            "    3 / 7 tests\n",
            "    4 / 7 tests\n",
            "    5 / 7 tests\n",
            "    6 / 7 tests\n",
            "    7 / 7 tests\n",
            "iteration: 6\n",
            "   training MTR...\n",
            "   training GS...\n",
            "   training LS...\n",
            "   training Marlena...\n",
            "    1 / 7 tests\n",
            "    2 / 7 tests\n",
            "    3 / 7 tests\n",
            "    4 / 7 tests\n",
            "    5 / 7 tests\n",
            "    6 / 7 tests\n",
            "    7 / 7 tests\n",
            "iteration: 7\n",
            "   training MTR...\n",
            "   training GS...\n",
            "   training LS...\n",
            "   training Marlena...\n",
            "    1 / 7 tests\n",
            "    2 / 7 tests\n",
            "    3 / 7 tests\n",
            "    4 / 7 tests\n",
            "    5 / 7 tests\n",
            "    6 / 7 tests\n",
            "    7 / 7 tests\n",
            "iteration: 8\n",
            "   training MTR...\n",
            "   training GS...\n",
            "   training LS...\n",
            "   training Marlena...\n",
            "    1 / 7 tests\n",
            "    2 / 7 tests\n",
            "    3 / 7 tests\n",
            "    4 / 7 tests\n",
            "    5 / 7 tests\n",
            "    6 / 7 tests\n",
            "    7 / 7 tests\n",
            "iteration: 9\n",
            "   training MTR...\n",
            "   training GS...\n",
            "   training LS...\n",
            "   training Marlena...\n",
            "    1 / 7 tests\n",
            "    2 / 7 tests\n",
            "    3 / 7 tests\n",
            "    4 / 7 tests\n",
            "    5 / 7 tests\n",
            "    6 / 7 tests\n",
            "    7 / 7 tests\n",
            "iteration: 10\n",
            "   training MTR...\n",
            "   training GS...\n",
            "   training LS...\n",
            "   training Marlena...\n",
            "    1 / 7 tests\n",
            "    2 / 7 tests\n",
            "    3 / 7 tests\n",
            "    4 / 7 tests\n",
            "    5 / 7 tests\n",
            "    6 / 7 tests\n",
            "    7 / 7 tests\n",
            "iteration: 11\n",
            "   training MTR...\n",
            "   training GS...\n",
            "   training LS...\n",
            "   training Marlena...\n",
            "    1 / 7 tests\n",
            "    2 / 7 tests\n",
            "    3 / 7 tests\n",
            "    4 / 7 tests\n",
            "    5 / 7 tests\n",
            "    6 / 7 tests\n",
            "    7 / 7 tests\n",
            "iteration: 12\n",
            "   training MTR...\n",
            "   training GS...\n",
            "   training LS...\n",
            "   training Marlena...\n",
            "    1 / 7 tests\n",
            "    2 / 7 tests\n",
            "    3 / 7 tests\n",
            "    4 / 7 tests\n",
            "    5 / 7 tests\n",
            "    6 / 7 tests\n",
            "    7 / 7 tests\n",
            "iteration: 13\n",
            "   training MTR...\n",
            "   training GS...\n",
            "   training LS...\n",
            "   training Marlena...\n",
            "    1 / 7 tests\n",
            "    2 / 7 tests\n",
            "    3 / 7 tests\n",
            "    4 / 7 tests\n",
            "    5 / 7 tests\n",
            "    6 / 7 tests\n",
            "    7 / 7 tests\n",
            "iteration: 14\n",
            "   training MTR...\n",
            "   training GS...\n",
            "   training LS...\n",
            "   training Marlena...\n",
            "    1 / 6 tests\n",
            "    2 / 6 tests\n",
            "    3 / 6 tests\n",
            "    4 / 6 tests\n",
            "    5 / 6 tests\n",
            "    6 / 6 tests\n",
            "iteration: 15\n",
            "   training MTR...\n",
            "   training GS...\n",
            "   training LS...\n",
            "   training Marlena...\n",
            "    1 / 6 tests\n",
            "    2 / 6 tests\n",
            "    3 / 6 tests\n",
            "    4 / 6 tests\n",
            "    5 / 6 tests\n",
            "    6 / 6 tests\n",
            "MTR| mae:  [0.049 0.046 0.037] | ruleL: 7.0 | TIME: 0.1303810755411784 | Coverage: 0.13193499622071048 | avg estimators: 93.579 / 100.0\n",
            " GS| mae:  [0.091 0.101 0.067] | ruleL: 3.5587301587301585 | TIME: 0.0006571811342996265 | Coverage: 0.23605442176870745\n",
            " LS| mae:  [0.091 0.102 0.054] | ruleL: 2.334920634920635 | TIME: 2.8968466130513995 | Coverage: 0.3292894935752078\n",
            "MAR| mae:  [0.05  0.059 0.046] | ruleL: 4.815873015873016 | TIME: 0.11660320191156297 | Coverage: 0.1638321995464852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getCsv(name, maeResults_all, t_n):\n",
        "  df = pd.DataFrame()\n",
        "  df['targets'] = list(t_n)\n",
        "  for key in maeResults_all.keys():\n",
        "    d=[]\n",
        "    [d.append(str(round(x, 5))) for x in np.array(maeResults_all[key]).mean(axis=0)]\n",
        "    print(d)\n",
        "    df[key] = [str(x) for x in d]\n",
        "  df.to_csv(name+'.csv', index=False)"
      ],
      "metadata": {
        "id": "M5WKUWP7toRO"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('students.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    columns = ['method']\n",
        "    [columns.append(x) for x in t_n]\n",
        "    writer.writerow(columns)\n",
        "    for key in maeResults_all.keys():\n",
        "      d=[key]\n",
        "      [d.append(round(x, 5)) for x in np.array(maeResults_all[key]).mean(axis=0)]\n",
        "      writer.writerow(d)"
      ],
      "metadata": {
        "id": "AtdRGFL8bD4-"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "getCsv('mae', maeResults_all, t_n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAEpc9iA40ON",
        "outputId": "d19ef832-7d84-40f5-b0ca-48c1ad47fe69"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0.26131', '0.24489', '0.19292']\n",
            "['0.0934', '0.10087', '0.06185']\n",
            "['0.09749', '0.10911', '0.0548']\n",
            "['0.05124', '0.05787', '0.04744']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.array(maeResults_all['MTR']).mean(axis=0))\n",
        "print(np.array(maeResults_all['GS']).mean(axis=0))\n",
        "print(np.array(maeResults_all['LS']).mean(axis=0))\n",
        "print(np.array(maeResults_all['MARLENA']).mean(axis=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gkesvq7o4Xqc",
        "outputId": "a50cb2a8-b080-4c40-c0ec-6adcf56b9763"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.26131443 0.24488955 0.19292454]\n",
            "[0.09340469 0.10086946 0.06185448]\n",
            "[0.0974892  0.10911252 0.05479754]\n",
            "[0.05123746 0.05787344 0.04743976]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# slump"
      ],
      "metadata": {
        "id": "_mm1YfhG8rzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "slump_data = arff.loadarff('slump.arff')\n",
        "slump_df = pd.DataFrame(slump_data[0])\n",
        "\n",
        "# get column names\n",
        "column_names = slump_df.columns\n",
        "\n",
        "# get data/target names\n",
        "f_n = column_names[:7]\n",
        "t_n = column_names[7:]\n",
        "\n",
        "X = slump_df[f_n]\n",
        "y = slump_df[t_n]\n",
        "\n",
        "# convert to numpy\n",
        "X = X.to_numpy()\n",
        "y = y.to_numpy()\n",
        "\n",
        "# scale target values\n",
        "scaler = MinMaxScaler()\n",
        "y = scaler.fit_transform(y)"
      ],
      "metadata": {
        "id": "qwIPdibnkDqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# andro"
      ],
      "metadata": {
        "id": "FC0ATmtZRjYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############\n",
        "# andro data 49x30, 6 targets\n",
        "############\n",
        "\n",
        "# load data\n",
        "andro_data = arff.loadarff('andro.arff')\n",
        "andro_df = pd.DataFrame(andro_data[0])\n",
        "\n",
        "# get column names\n",
        "column_names = andro_df.columns\n",
        "\n",
        "# get data/target names\n",
        "f_n = column_names[:30]\n",
        "t_n = column_names[30:]\n",
        "\n",
        "X = andro_df[f_n]\n",
        "y = andro_df[t_n]\n",
        "\n",
        "# convert to numpy\n",
        "X = X.to_numpy()\n",
        "y = y.to_numpy()\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "y = scaler.fit_transform(y)\n",
        "\n",
        "# kf = KFold(n_splits=2, shuffle=True, random_state=42)\n",
        "# counter = 1\n",
        "# for train_index, test_index in kf.split(X):\n",
        "#   X_train, X_test = X[train_index], X[test_index]\n",
        "#   y_train, y_test = y[train_index], y[test_index]\n",
        "#   print(\"iteration:\", counter)\n",
        "#   counter += 1\n",
        "#   doTest(X_train, X_test, y_train, y_test, f_n, t_n, 0.1)\n",
        "#   break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z993BmywRwaK",
        "outputId": "fe304d24-1c28-4df2-9153-888c84a1efe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration: 1\n",
            "training MTR...\n",
            "training GS...\n",
            "training LS...\n",
            "training Marlena...\n",
            "1 / 25 tests\n",
            "2 / 25 tests\n",
            "3 / 25 tests\n",
            "4 / 25 tests\n",
            "5 / 25 tests\n",
            "6 / 25 tests\n",
            "7 / 25 tests\n",
            "8 / 25 tests\n",
            "9 / 25 tests\n",
            "10 / 25 tests\n",
            "11 / 25 tests\n",
            "12 / 25 tests\n",
            "13 / 25 tests\n",
            "14 / 25 tests\n",
            "15 / 25 tests\n",
            "16 / 25 tests\n",
            "17 / 25 tests\n",
            "18 / 25 tests\n",
            "19 / 25 tests\n",
            "20 / 25 tests\n",
            "21 / 25 tests\n",
            "22 / 25 tests\n",
            "23 / 25 tests\n",
            "24 / 25 tests\n",
            "25 / 25 tests\n",
            "MTR| mae:  [0. 0. 0. 0. 0. 0.] | ruleL: 30.0 | TIME: 0.12080965042114258 | Coverage: 0.0192 | avg estimators: 100.0 / 100\n",
            " GS| mae:  [0.059 0.055 0.057 0.059 0.058 0.055] | ruleL: 3.88 | TIME: 0.0005713367462158203 | Coverage: 0.20960000000000004\n",
            " LS| mae:  [0.061 0.066 0.054 0.057 0.057 0.055] | ruleL: 3.8 | TIME: 2.6210045337677004 | Coverage: 0.20160000000000008\n",
            "MAR| mae:  [0.072 0.075 0.102 0.102 0.061 0.057] | ruleL: 5.0 | TIME: 0.09715690612792968 | Coverage: 0.08800000000000002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# osales NaN values"
      ],
      "metadata": {
        "id": "oDEIXBSjXL5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ############\n",
        "# # osales 639x413, 12 targets\n",
        "# ############\n",
        "\n",
        "# load data\n",
        "osales_data = arff.loadarff('osales.arff')\n",
        "osales_df = pd.DataFrame(osales_data[0])\n",
        "osales_df=osales_df.dropna()\n",
        "\n",
        "# get column names\n",
        "column_names = osales_df.columns\n",
        "\n",
        "# get data/target names\n",
        "f_n = column_names[:30]\n",
        "t_n = column_names[30:]\n",
        "\n",
        "X = osales_df[f_n]\n",
        "y = osales_df[t_n]\n",
        "\n",
        "# convert to numpy\n",
        "X = X.to_numpy()\n",
        "y = y.to_numpy()\n",
        "\n",
        "kf = KFold(n_splits=2, shuffle=True, random_state=42)\n",
        "counter = 1\n",
        "for train_index, test_index in kf.split(X):\n",
        "  X_train, X_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "  print(\"iteration:\", counter)\n",
        "  counter += 1\n",
        "  doTest(X_train, X_test, y_train, y_test, f_n, t_n, 100)\n",
        "  break"
      ],
      "metadata": {
        "id": "syI2DCs7XOGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# wq"
      ],
      "metadata": {
        "id": "vQNcHFD1VyuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############\n",
        "# wq 1060x16, 14 targets\n",
        "############\n",
        "\n",
        "# load data\n",
        "wq_data = arff.loadarff('wq.arff')\n",
        "wq_df = pd.DataFrame(wq_data[0])\n",
        "\n",
        "# get column names\n",
        "column_names = wq_df.columns\n",
        "\n",
        "# get data/target names\n",
        "f_n = column_names[:5]\n",
        "t_n = column_names[20:]\n",
        "\n",
        "X = wq_df[f_n]\n",
        "y = wq_df[t_n]\n",
        "\n",
        "# convert to numpy\n",
        "X = X.to_numpy()\n",
        "y = y.to_numpy()\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "y = scaler.fit_transform(y)\n",
        "\n",
        "# kf = KFold(n_splits=30, shuffle=True, random_state=42)\n",
        "# counter = 1\n",
        "# for train_index, test_index in kf.split(X):\n",
        "#   X_train, X_test = X[train_index], X[test_index]\n",
        "#   y_train, y_test = y[train_index], y[test_index]\n",
        "#   print(\"iteration:\", counter)\n",
        "#   counter += 1\n",
        "#   doTest(X_train, X_test, y_train, y_test, f_n, t_n, 0.1)\n",
        "#   break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7f7BDJ3V1pC",
        "outputId": "7bbeb1d6-3d5b-4e87-f7b9-60f371ba3d13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration: 1\n",
            "training MTR...\n",
            "training GS...\n",
            "training LS...\n",
            "training Marlena...\n",
            "1 / 36 tests\n",
            "2 / 36 tests\n",
            "3 / 36 tests\n",
            "4 / 36 tests\n",
            "5 / 36 tests\n",
            "6 / 36 tests\n",
            "7 / 36 tests\n",
            "8 / 36 tests\n",
            "9 / 36 tests\n",
            "10 / 36 tests\n",
            "11 / 36 tests\n",
            "12 / 36 tests\n",
            "13 / 36 tests\n",
            "14 / 36 tests\n",
            "15 / 36 tests\n",
            "16 / 36 tests\n",
            "17 / 36 tests\n",
            "18 / 36 tests\n",
            "19 / 36 tests\n",
            "20 / 36 tests\n",
            "21 / 36 tests\n",
            "22 / 36 tests\n",
            "23 / 36 tests\n",
            "24 / 36 tests\n",
            "25 / 36 tests\n",
            "26 / 36 tests\n",
            "27 / 36 tests\n",
            "28 / 36 tests\n",
            "29 / 36 tests\n",
            "30 / 36 tests\n",
            "31 / 36 tests\n",
            "32 / 36 tests\n",
            "33 / 36 tests\n",
            "34 / 36 tests\n",
            "35 / 36 tests\n",
            "36 / 36 tests\n",
            "MTR| mae:  [0.004 0.007 0.004 0.005 0.008 0.007 0.006 0.004 0.007 0.008] | ruleL: 5.0 | TIME: 0.14439587460623848 | Coverage: 0.027006172839506182 | avg estimators: 98.972 / 100\n",
            " GS| mae:  [0.03  0.053 0.018 0.034 0.081 0.051 0.035 0.027 0.043 0.039] | ruleL: 3.7222222222222223 | TIME: 0.0005907615025838217 | Coverage: 0.09259259259259256\n",
            " LS| mae:  [0.019 0.038 0.016 0.027 0.053 0.034 0.021 0.011 0.019 0.026] | ruleL: 2.5555555555555554 | TIME: 2.626927786403232 | Coverage: 0.1466049382716049\n",
            "MAR| mae:  [0.02  0.027 0.014 0.022 0.041 0.03  0.023 0.018 0.026 0.025] | ruleL: 3.9722222222222223 | TIME: 0.24781525797314113 | Coverage: 0.035493827160493825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# facebook"
      ],
      "metadata": {
        "id": "pMpd5Sw9st7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############\n",
        "# facebook 500x14, 4 targets\n",
        "############\n",
        "fb_df = pd.read_csv('dataset_Facebook.csv', sep=';')#, nrows=200)\n",
        "\n",
        "# fill NaN\n",
        "fb_df['like'].fillna(0,inplace=True)\n",
        "fb_df['share'].fillna(0,inplace=True)\n",
        "fb_df['Paid'].fillna(0,inplace=True)\n",
        "fb_df.drop(['Type'], inplace=True, axis=1)\n",
        "\n",
        "\n",
        "# get column names\n",
        "column_names = fb_df.columns\n",
        "\n",
        "# get data/target names\n",
        "f_n = column_names[:14]\n",
        "#t_n = ['comment', 'share']\n",
        "t_n = column_names[14:]\n",
        "\n",
        "X = fb_df[f_n]\n",
        "y = fb_df[t_n]\n",
        "\n",
        "# convert to numpy\n",
        "X = X.to_numpy()\n",
        "y = y.to_numpy()\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "y = scaler.fit_transform(y)\n",
        "\n",
        "# kf = KFold(n_splits=25, shuffle=True, random_state=42)\n",
        "# counter = 1\n",
        "# for train_index, test_index in kf.split(X):\n",
        "#   X_train, X_test = X[train_index], X[test_index]\n",
        "#   y_train, y_test = y[train_index], y[test_index]\n",
        "#   print(\"iteration:\", counter)\n",
        "#   counter += 1\n",
        "#   doTest(X_train, X_test, y_train, y_test, f_n, t_n, 0.1)\n",
        "#   break"
      ],
      "metadata": {
        "id": "FZZIPiyIZAu_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f51dc50a-7c1c-48c8-80f2-c0d355f84dde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration: 1\n",
            "training MTR...\n",
            "training GS...\n",
            "training LS...\n",
            "training Marlena...\n",
            "1 / 20 tests\n",
            "2 / 20 tests\n",
            "3 / 20 tests\n",
            "4 / 20 tests\n",
            "5 / 20 tests\n",
            "6 / 20 tests\n",
            "7 / 20 tests\n",
            "8 / 20 tests\n",
            "9 / 20 tests\n",
            "10 / 20 tests\n",
            "11 / 20 tests\n",
            "12 / 20 tests\n",
            "13 / 20 tests\n",
            "14 / 20 tests\n",
            "15 / 20 tests\n",
            "16 / 20 tests\n",
            "17 / 20 tests\n",
            "18 / 20 tests\n",
            "19 / 20 tests\n",
            "20 / 20 tests\n",
            "MTR| mae:  [0.004 0.004 0.004 0.004] | ruleL: 14.0 | TIME: 0.3586753010749817 | Coverage: 0.05000000000000001 | avg estimators: 99.6 / 100\n",
            " GS| mae:  [0.005 0.007 0.008 0.007] | ruleL: 4.2 | TIME: 0.0005957722663879394 | Coverage: 0.14500000000000005\n",
            " LS| mae:  [0.005 0.008 0.006 0.007] | ruleL: 2.35 | TIME: 2.575191414356232 | Coverage: 0.32999999999999996\n",
            "MAR| mae:  [0.004 0.005 0.005 0.005] | ruleL: 6.2 | TIME: 0.17716871500015258 | Coverage: 0.07500000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# River flow"
      ],
      "metadata": {
        "id": "l-74I50D6M-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# 9125x576 + 8\n",
        "RF2_df = pd.read_csv('RF2.csv')\n",
        "RF2_df = RF2_df.dropna(axis=0)\n",
        "\n",
        "RF2_cols = RF2_df.columns\n",
        "RF2_df = RF2_df[RF2_cols[1:]].reset_index(drop=True)\n",
        "RF2_df = RF2_df.iloc[:200]\n",
        "\n",
        "RF2_cols = RF2_df.columns\n",
        "f_n = RF2_cols[:576]\n",
        "t_n = RF2_cols[576:]\n",
        "f_n = f_n[:15]\n",
        "t_n = t_n[:5]\n",
        "\n",
        "X = RF2_df[f_n]\n",
        "y = RF2_df[t_n]\n",
        "\n",
        "# convert to numpy\n",
        "X = X.to_numpy()\n",
        "y = y.to_numpy()\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "y = scaler.fit_transform(y)\n",
        "\n",
        "# kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "# counter = 1\n",
        "# for train_index, test_index in kf.split(X):\n",
        "#   X_train, X_test = X[train_index], X[test_index]\n",
        "#   y_train, y_test = y[train_index], y[test_index]\n",
        "#   print(\"iteration:\", counter)\n",
        "#   counter += 1\n",
        "#   doTest(X_train, X_test, y_train, y_test, f_n, t_n, 0.08)\n",
        "#   break"
      ],
      "metadata": {
        "id": "CcdQaKQX9LGl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abb296a7-446a-40b0-f6ff-a1141c92fd3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration: 1\n",
            "training MTR...\n",
            "training GS...\n",
            "training LS...\n",
            "training Marlena...\n",
            "1 / 20 tests\n",
            "2 / 20 tests\n",
            "3 / 20 tests\n",
            "4 / 20 tests\n",
            "5 / 20 tests\n",
            "6 / 20 tests\n",
            "7 / 20 tests\n",
            "8 / 20 tests\n",
            "9 / 20 tests\n",
            "10 / 20 tests\n",
            "11 / 20 tests\n",
            "12 / 20 tests\n",
            "13 / 20 tests\n",
            "14 / 20 tests\n",
            "15 / 20 tests\n",
            "16 / 20 tests\n",
            "17 / 20 tests\n",
            "18 / 20 tests\n",
            "19 / 20 tests\n",
            "20 / 20 tests\n",
            "MTR| mae:  [0.021 0.019 0.017 0.018 0.021] | ruleL: 15.0 | TIME: 0.13760486841201783 | Coverage: 0.05000000000000001 | avg estimators: 97.3 / 100\n",
            " GS| mae:  [0.02  0.04  0.027 0.016 0.031] | ruleL: 4.55 | TIME: 0.0005395770072937012 | Coverage: 0.09000000000000002\n",
            " LS| mae:  [0.014 0.04  0.016 0.012 0.016] | ruleL: 3.75 | TIME: 2.6330909371376037 | Coverage: 0.07250000000000004\n",
            "MAR| mae:  [0.01  0.029 0.016 0.009 0.015] | ruleL: 5.8 | TIME: 0.123377525806427 | Coverage: 0.06500000000000002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AVG OF K-FOLD\n",
        "#https://github.com/tsoumakas/mulan/blob/master/data/multi-target/andro.arff\n",
        "#https://github.com/tsoumakas/mulan/blob/master/data/multi-target/wq.arff\n",
        "#https://github.com/tsoumakas/mulan/blob/master/data/multi-target/osales.arff"
      ],
      "metadata": {
        "id": "A3BmNWAaNGY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test values"
      ],
      "metadata": {
        "id": "u0DP19b6XLot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "actualpreds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G55_KYJgxRk3",
        "outputId": "394fca4f-b055-42ca-98ce-eb8a4495b421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[24.  , 60.  , 45.82],\n",
              "       [24.  , 60.  , 45.82],\n",
              "       [24.  , 60.  , 45.82],\n",
              "       [24.  , 60.  , 45.82]])"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MTRpreds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrHkr8zvteK_",
        "outputId": "1491f2ab-5dd2-4491-ab72-755cf4143519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[13.5575,  2.685 ],\n",
              "        [37.44  ,  4.645 ],\n",
              "        [45.8797,  3.5429]],\n",
              "\n",
              "       [[13.5575,  2.685 ],\n",
              "        [37.44  ,  4.645 ],\n",
              "        [45.8797,  3.5429]],\n",
              "\n",
              "       [[13.5575,  2.685 ],\n",
              "        [37.44  ,  4.645 ],\n",
              "        [45.8797,  3.5429]],\n",
              "\n",
              "       [[13.5575,  2.685 ],\n",
              "        [37.44  ,  4.645 ],\n",
              "        [45.8797,  3.5429]]])"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_array = np.array([subarray[:,1] for subarray in MTRpreds])\n",
        "column_averages = np.mean(new_array, axis=0)\n",
        "column_averages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmbzBmHxtW3E",
        "outputId": "669f728c-0bfc-4f07-870f-0da157c34d73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.685 , 4.645 , 3.5429])"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(actualpreds[0])\n",
        "print(MTRpreds[0])\n",
        "print(GSpreds[0])\n",
        "print(LSpreds[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vi_KoanApL7T",
        "outputId": "e5f427cc-023d-4eb2-8d44-1d97845060c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[24.   60.   45.82]\n",
            "[[13.5575  2.685 ]\n",
            " [37.44    4.645 ]\n",
            " [45.8797  3.5429]]\n",
            "[16.68    42.815   38.35685]\n",
            "[12.38875 33.85    52.72455]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(calc_al_error(y_test[10], 0.1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtiMJcbihbGF",
        "outputId": "1a9476d4-3c7a-41cd-a1fb-3ac826ea4e95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.0500000000000003, 4.82, 4.93]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# experiments\n",
        "# mae, len, cov, time\n",
        "# k-fold\n",
        "# allowed_error []\n",
        "#https://github.com/intelligence-csd-auth-gr/LionLearn/blob/master/LionForests_Multi/experiments/C3.%20WaterQuality.ipynb"
      ],
      "metadata": {
        "id": "gubJb4qCE7mX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OLD"
      ],
      "metadata": {
        "id": "Zno7j6fmBz5L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "using MTR"
      ],
      "metadata": {
        "id": "rq63E5SmP6Hs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MTR_obj = MTR(model=None, X_train = X_train, X_test=X_test, y_train=y_train, y_test=y_test, feature_names=f_n, target_names=t_n)\n",
        "rule = MTR_obj.explain(instance, 5) # you can add as last arguement the allowed error\n",
        "featureLimits = MTR_obj.getFeatureLimits()\n",
        "decisionsAndErrors = MTR_obj.getDecisionsAndErros()\n",
        "print(decisionsAndErrors)\n",
        "print(rule)\n",
        "\n",
        "# this model will be used for L/G surrogate\n",
        "model = MTR_obj.getModel()\n",
        "predictions = model.predict(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qo-D_hAfP8PM",
        "outputId": "b17c0c1d-2f1c-46ed-d9dc-ff9699c2e733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "allowed_error [5 5 5]\n",
            "reduced_rules:  89 / 100\n",
            "[[13.5575, 2.685], [37.44, 4.645], [45.8797, 3.5429]]\n",
            "if 167.0<=Water<=168.5 & 904.0<=Coarse_Aggr<=917.5 & 0.0<=Slag<=0.05 & 801.5<=Fine_Aggr<=805.0 & 309.5<=Cemment<=310.0 & 142.5<=Fly_ash<=143.0 & 9.5<=SP<=10.0 then SLUMP_cm: 13.5575 +/- 2.685 error, FLOW_cm: 37.44 +/- 4.645 error, Compressive_Strength_Mpa: 45.8797 +/- 3.5429 error\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "using global surrogate"
      ],
      "metadata": {
        "id": "L-lG18OuP953"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GS = GlobalSurrogateTree(X_train, predictions, f_n)\n",
        "r, GSp = GS.rule(instance)\n",
        "print(GS.rule(instance))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaKyvBdFQBnt",
        "outputId": "978a4e42-0263-4469-da6f-991bab64607a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'Water': [['<=', 182.25]], 'Slag': [['<=', 66.39999961853027]], 'Coarse_Aggr': [['<=', 1048.2999877929688], ['>', 904.0]], 'Fly_ash': [['<=', 210.9499969482422]]}, array([16.68   , 42.815  , 38.35685]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "using local surrogate"
      ],
      "metadata": {
        "id": "Arqz8_w-QCtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LS = LocalSurrogateTree(X_train, predictions, f_n, 40) # neigns should be >= 10\n",
        "rl, LSp = LS.rule(instance)\n",
        "print(LS.rule(instance))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKoGZqfrQDCy",
        "outputId": "475fe8c0-6853-4196-8bdc-0bc6e47c4151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'Fly_ash': [['<=', 210.7123150630344], ['>', 34.602104331589345]], 'Water': [['<=', 181.24161005543618]], 'Cemment': [['>', 298.04265509501226]]}, array([12.38875, 33.85   , 52.72455]))\n"
          ]
        }
      ]
    }
  ]
}